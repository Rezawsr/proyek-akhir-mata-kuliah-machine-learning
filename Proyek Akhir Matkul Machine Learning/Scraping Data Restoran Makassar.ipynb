{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42419c56-2034-48e1-a50d-aec10c62e870",
   "metadata": {},
   "source": [
    "# Metode Pengumpulan Data\n",
    "\n",
    "> pada kernel ini saya melakukan scraping data ulasan restoran pada google maps Metode pengumpulan data yang digunakan adalah scraping data menggunakan library SerpApi. SerpApi adalah sebuah platform yang menyediakan API untuk melakukan scraping data pada berbagai platform seperti Google, Bing, dan lain sebagainya. Pada kernel ini, SerpApi digunakan untuk melakukan scraping data pada ulasan restoran yang ada di Makassar di Google Maps. Dengan menggunakan SerpApi, kita dapat dengan mudah mengambil data ulasan restoran secara otomatis tanpa harus melakukan pengambilan data secara manual satu persatu. Data yang berhasil diambil kemudian akan digunakan sebagai data latih dalam pembuatan model untuk melakukan klasifikasi sentimen ulasan restoran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9339ab6b-512d-43ff-8897-81e73763cfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-search-results\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
      "Requirement already satisfied: requests in ./opt/anaconda3/lib/python3.9/site-packages (from google-search-results) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->google-search-results) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->google-search-results) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->google-search-results) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->google-search-results) (3.3)\n",
      "Building wheels for collected packages: google-search-results\n",
      "  Building wheel for google-search-results (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32016 sha256=fc1f67a9d50d36f7899d8eec333cf8d37830343109194f74e2159cf09527245e\n",
      "  Stored in directory: /Users/user/Library/Caches/pip/wheels/68/8e/73/744b7d9d7ac618849d93081a20e1c0deccd2aef90901c9f5a9\n",
      "Successfully built google-search-results\n",
      "Installing collected packages: google-search-results\n",
      "Successfully installed google-search-results-2.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aaa6bd4-8207-4edf-b4cd-155de79e6de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpapi import GoogleSearch\n",
    "from urllib.parse import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d219c33-b67d-4b3e-b2c7-93b207678c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Nama': 'Hong Kong Restaurant', 'data_id': '0x2dbf02a38a29c593:0xfc49c39b6e8ddd5d', 'total_reviews': 668}, {'Nama': 'RM. Pallu Kaloa 1', 'data_id': '0x2dbf029fa0a00d7f:0xe942ca9778839c9f', 'total_reviews': 1176}, {'Nama': 'Rumah Makan Patene', 'data_id': '0x2dbf02a4c9b715eb:0xee9b995f7f676d21', 'total_reviews': 335}, {'Nama': 'RICH TASTE', 'data_id': '0x2dbf02a1765eedad:0x96c967adaeea9e56', 'total_reviews': 417}]\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "  \"engine\": \"google_maps\",\n",
    "  \"q\": \"restoran\", # objek yang dicari\n",
    "  \"ll\": \"@-5.1229484,119.4022719,15z\", #koordinat tempat sekitar\n",
    "  \"type\": \"search\",\n",
    "  \"api_key\": \"1a6caebeae3bc6ec43936f11cbb04fe89cd9a32619a2d8f5ae30b8fc552e62d6\"\n",
    "}\n",
    "\n",
    "\n",
    "search = GoogleSearch(params)\n",
    "\n",
    "lIdx = 0 # indeks yang ditampilkan dari data\n",
    "lSum = 7 # Batas jumlah data yang ditampilkan\n",
    "local_results = []\n",
    "\n",
    "while lIdx  <= lSum:\n",
    "    results = search.get_dict()\n",
    "    if \"local_results\" in results:\n",
    "        for Result in results[\"local_results\"]:\n",
    "            lIdx += 1\n",
    "            if lIdx <= lSum:\n",
    "                if isinstance(Result, dict):\n",
    "                    # seleksi data (jangan ambil data jika jumlah review < 200 )\n",
    "                    reviews = Result.get(\"reviews\", 0)\n",
    "                    if isinstance(reviews, str):\n",
    "                        reviews = int(reviews.replace(\",\", \"\"))\n",
    "                    if reviews < 100:\n",
    "                        continue\n",
    "                    # Append data sesuai dengan batas jumlah yang sudah ditentukan\n",
    "                    local_results.append({'Nama': Result[\"title\"],\n",
    "                                          'data_id': Result[\"data_id\"],\n",
    "                                          'total_reviews': reviews})\n",
    "    #menghilangkan pagination pada web, sehingga data yang terambil bisa banyak\n",
    "    if \"next\" in results.get(\"serpapi_pagination\", {}):\n",
    "        # Akan mengubah parameter dari 'GoogleSearch()' dengan isi parameter dari halaman selanjutnya\n",
    "        search.params_dict.update(dict(parse_qsl(urlsplit(results.get(\"serpapi_pagination\").get(\"next\")).query)))\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(local_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e39608a8-500d-4ae8-b254-cc782dc09cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Nama': 'Hong Kong Restaurant', 'data_id': '0x2dbf02a38a29c593:0xfc49c39b6e8ddd5d', 'total_reviews': 668}\n",
      "{'Nama': 'RM. Pallu Kaloa 1', 'data_id': '0x2dbf029fa0a00d7f:0xe942ca9778839c9f', 'total_reviews': 1176}\n",
      "{'Nama': 'Rumah Makan Patene', 'data_id': '0x2dbf02a4c9b715eb:0xee9b995f7f676d21', 'total_reviews': 335}\n",
      "{'Nama': 'RICH TASTE', 'data_id': '0x2dbf02a1765eedad:0x96c967adaeea9e56', 'total_reviews': 417}\n"
     ]
    }
   ],
   "source": [
    "for LR in local_results:\n",
    "  print(LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea6e832f-286a-4fb3-a272-612a349698df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Restoran_name':[],\n",
    "        'name':[],\n",
    "        'rating':[],\n",
    "        'review':[]}\n",
    "\n",
    "for LR in local_results:\n",
    "  \n",
    "  params = {\n",
    "    \"engine\": \"google_maps_reviews\",\n",
    "    \"data_id\": \"\",\n",
    "    \"api_key\": \"08851987a422f702d52c8ac291e6a65769587f7b7fff05544fa7344c8d289dfe\"\n",
    "  }\n",
    "  \n",
    "  params[\"data_id\"] = LR['data_id']\n",
    "\n",
    "  search = GoogleSearch(params)\n",
    "\n",
    "  lIdx = 0 # Angka indeks dari data\n",
    "  lSum = 30 # Batas jumlah data yang ditampilkan\n",
    "\n",
    "  while lIdx <= lSum:\n",
    "    results = search.get_dict()\n",
    "\n",
    "    for Result in results[\"reviews\"]:\n",
    "      lIdx += 1\n",
    "\n",
    "      if lIdx <= lSum:\n",
    "        # Append data sesuai dengan batas jumlah yang sudah ditentukan\n",
    "        data['Restoran_name'].append(LR['Nama']);\n",
    "        data['name'].append(Result[\"user\"][\"name\"]);\n",
    "        data['rating'].append(Result[\"rating\"]);\n",
    "        data['review'].append(Result[\"snippet\"]);\n",
    "\n",
    "    #menghilangkan pagination pada web, sehingga data yang terambil bisa banyak\n",
    "    if \"next\" in results.get(\"serpapi_pagination\", {}):\n",
    "      # Akan mengubah parameter dari 'GoogleSearch()' dengan isi parameter dari halaman selanjutnya\n",
    "      search.params_dict.update(dict(parse_qsl(urlsplit(results.get(\"serpapi_pagination\").get(\"next\")).query)))\n",
    "\n",
    "    else:\n",
    "      break\n",
    "    \n",
    "review_original = data['review']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c73b7f-3247-40cb-a177-fb4f60a601c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# create directory if it does not exist\n",
    "if not os.path.exists('File CSV'):\n",
    "    os.makedirs('File CSV')\n",
    "\n",
    "dfScrap = pd.DataFrame(data)\n",
    "dfScrap.to_csv('File CSV/reviewrestoranmakassar.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
